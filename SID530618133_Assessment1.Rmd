---
title: "DATA3888 Reef Assignment"
output: 
  html_document:
    code_folding: show
    theme: cerulean
    toc: yes
    toc_float:
      collapsed: true
date: "2025-03-11"
author: "530618133"
bibliography: citations.bib
embed-resources: true
---

```{r, include=FALSE}
# These are all the added libraries for this project.
library(viridis)
library(tidyverse)
library(ncdf4)
library(gridExtra)
library(tidyverse)
library(class)
library(cvTools)
library(randomForest)
library(caret)
library(RNetCDF)
library(sf)
library(lubridate)
```

![Turtle in Coral Reef Image (from Pixabay)](turtleInReef.jpg)

# Outline
Coral Reefs are known for their natural beauty, with vibrant colors in the oceans, nearby underwater species like Turtles and Fish (as in the picture) around living simultaneously in beautiful harmony. However, mounting environmental issues like that of Climate Change can cause shifts on the Earths surface and sea-surface temperature, and threaten these precious natural ecosystems. Between 2014-2017 there was an example of such an event which led to major coral bleaching known as El Niño.

For this project we will be serving two clients who each required us to carry out specific analysis for particular queries. The first has asked us to first assess a claim in regards to Tropical Mid-Lateral Reefs having higher probabilities of Coral Bleaching in this time. Furthermore, a second client asked us to assess whether environmental variables measured four years prior are less, equal, or more useful than environmental variables measured at the same time to predict coral bleaching. This report analyses these claims through various maps and line charts in Part One, and Random Forest classifications and resultant confusion matrix for Part Two, and generally gives insight into the effects of El Niño.

We encourage the reader to hide all code until necessary to read for document readability purposes. Please note the document is written in the third-person to represent the company / group I am working for in a real life scenario, so we's are used instead of I's.

## General Processes
Our objectives for this project are to provide our clients with their required information and data visualizations, but furthermore, carry out all instructions on the Introductory Document on Canvas sufficiently, i.e, setting the seed to 3888 where necessary in R.

## Crediting
Where we use any external resources in the form of websites we will make clear of what we have used by commenting on it in R where needed and including it in the bibtex file. Furthermore, if we use Artificial Intelligence (AI) chat-bots we will be fully transparent about what and how it was used, and will ensure as specified in the Instructions we will not use AI to "generate all or part of our assessment tasks for us" and any usage will also be properly acknowledged and cited on the bibtex file.

## Part One Data Cleaning and Analysis

Our client asked us to explore the claim that "Tropical Mid-Lateral Reefs have a higher probability of Coral Bleaching between 2014-2017 (time of El Niño)". We aim to do so with a plethora of visualizations, and if we believe this to be the case, we aim to explore potential reasons why. Below is the data cleaning and analysis for this process.

## Exploratory Data Analysis
Below is the Pre-processing and Exploratory Data Analysis for Part One. We have already loaded in libraries neccesary on the R file.  Overall we were pleased with the reefCortadDataYears dataset after some basic NA row removal, subsetting for years 2014 to 2018 and the variables we required.

Throughout this HTML file, we have tried to optimize and clean the interwoven R code where necessary reflecting on it where needed. We have also left comments to describe what variables mean, and have a designated R code chunk for cleaning of the data needed for both parts at the top of the Markdown file. Throughout the R code we will provide thorough comments for clarity for our clients benefit.

```{r}
# This chunk loads in data for the first part and cleans where necessary.

# Part One
# This loads in the csv file for part one's client.
reefCortadData <- read.csv("Reef_Check_with_cortad_variables_with_annual_rate_of_SST_change.csv")
# We kept only columns we found of interest.
reefCortadData <- reefCortadData[, c("Reef.Name", "Year", "Latitude.Degrees", "Longitude.Degrees","Average_bleaching", "TSA_Mean", "Temperature_Mean", "Diversity")]
# The client required data from years 2014-2017 so we filtered:
reefCortadDataYears <- filter(reefCortadData, Year >= 2014 & Year < 2018)
# Removing na rows
reefCortadDataYears <- na.omit(reefCortadDataYears)
# We have decided to not remove Average bleaching variable rows of 0 as we want to keep these rows for the other graphs, just remove them here so that reefs aren't duplicated. It just produces each Reefs average in one of their rows.
```

For this variable Average_bleaching below we feel we will need to omit the 0 values as there seems to be quite a lot, but include them for the other graphs as there seems to be quite a lot of them. We imagine they're related to one average for each Reef. This process is important as it will be used to explore the Reef's average bleaching to distinguish Tropical Mid-latitude and outer zones.

```{r}
# Here is some basic EDA for Part One, a boxplot showing average bleaching
ggplot() + geom_boxplot(data = reefCortadDataYears, aes(x=Average_bleaching))
```

Below we experiment with the template map to model latitude, longitude and diversity. We are interested to explore in whether Tropical Mid-latitude States over time have noticeable trends with Diversity. It is clear that there are some association of more diversity in the mid-latitude.

```{r}
# This chunk is used to model diversity on a world map
ggplot() + geom_polygon(data = map_data("world"), aes(x=long, y = lat, group = group), alpha=0.3) + geom_point(data = reefCortadDataYears, aes(x=Longitude.Degrees, y=Latitude.Degrees, color = Diversity))
```

I wanted to model Temperature to check the distribution for outliers. There were none of note it seemed. We also repeated the process for TSA, and there weren't any of note. These may be used to point to coral bleaching occurring in Midlatitude vs outer zones.

```{r}
# This chunk is used to model temperature mean by year
ggplot(reefCortadDataYears, aes(x = as.factor(Year), y = Temperature_Mean)) + 
  geom_boxplot()
```

```{r}
# This chunk is used to model tsa mean by year
ggplot(reefCortadDataYears, aes(x = as.factor(Year), y = TSA_Mean)) + 
  geom_boxplot()
```
We wanted to check for association between two variables for potential future usage, and found some weak-moderate association. It did appear that a temperature increase did show signs of a tsa increase as inferenced with a linear model.
```{r}
# This chunk is used to model temperature mean vs tsa mean
ggplot(reefCortadDataYears, aes(x = Temperature_Mean, y = TSA_Mean)) + geom_point() + geom_smooth(method="lm")
```

### Conclusion for Part One Analysis and Cleaning
After exploring some of the data cleaning, wrangling, and exploratory data analysis for part one we were able to analyse certain variables that will be of use for dissecting client one's claim.

## Part Two Data Cleaning and Analysis

Our client asked us to compare data from four years prior and data aligned simultaneously with bleaching data, seeing which is more effective at predicting bleaching in the Great Barrier Reef. We aim to do so with a plethora of visualizations, and if we believe this to be the case, we aim to explore why. Below is the data cleaning and analysis for this process.

## Exploratory Data Analysis
Below is the Pre-processing and Exploratory Data Analysis. It involved some of the code from laboratory one used to load it in and make it able to be manipulated. As this step will likely use a data classification model such as Random Forest there will be less of a focus on association between variables and more regarding

```{r}
# Part Two
# Lots of the below lines are from lab 1, helping to load in the data
eReefs_nc = nc_open(
"https://thredds.ereefs.aims.gov.au/thredds/dodsC/
GBR4_H2p0_B3p1_Cq3b_Dhnd/annual.nc?zc[1],
latitude[0:1:722],longitude[0:1:490],
temp[0:1:9][1][0:1:722][0:1:490],
TOTAL_NITROGEN[0:1:9][1][0:1:722][0:1:490],
MA_N[0:1:9][0:1:722][0:1:490],
PH[0:1:9][1][0:1:722][0:1:490],
salt[0:1:9][1][0:1:722][0:1:490],
time[0:1:9]")

# Longitude and Latitude
lat = ncdf4::ncvar_get(eReefs_nc, "latitude")
long = ncdf4::ncvar_get(eReefs_nc, "longitude")

# Time
time = ncdf4::ncvar_get(eReefs_nc, "time")
tunits = ncdf4::ncatt_get(eReefs_nc, "time", "units")
cf = CFtime::CFtime(tunits$value, calendar = "standard", time)
timestamps = CFtime::as_timestamp(cf) 
timestamps = as.Date(timestamps, format = "%Y-%m-%d") 

# Explanatory variables
temp = ncdf4::ncvar_get(eReefs_nc, "temp")
salt = ncdf4::ncvar_get(eReefs_nc, "salt")
total_n = ncdf4::ncvar_get(eReefs_nc, "TOTAL_NITROGEN")
ma_n = ncdf4::ncvar_get(eReefs_nc, "MA_N")
ph = ncdf4::ncvar_get(eReefs_nc, "PH")

# Convert data to data.frame
eReefs_df = expand.grid(long = long, lat = lat, time = timestamps) %>%
    mutate(temp = as.vector(temp), salt = as.vector(salt), total_n = as.vector(total_n), ma_n = as.vector(ma_n), ph = as.vector(ph))

# filter out when temp or salt is NaN
eReefs_noNan = eReefs_df |>
    filter(!is.nan(temp), !is.nan(salt))

# Loads in the bleaching surveys data-set, and stores as sf
bleachingData <- read.csv("bleachingSurveys.csv")
bleaching_sf = st_as_sf(bleachingData, coords = c("longitude", "latitude"), crs = 4326)
# Removing unneccesary columns
bleaching_sf <- subset(bleaching_sf, select = -c(UNIQUE_ID, reef_NAME, source, method, depth))
                       
# Stores eReefs as sf too
eReefs_sf = st_as_sf(eReefs_noNan, coords = c("long", "lat"), crs = 4326)

# Joins bleaching sf with eReefs sf
joined_sf = st_join(bleaching_sf, eReefs_sf, join = st_is_within_distance, dist = 1000,
    left = TRUE)

# Filters datasets based on same time of surveyDate and time variables.
joined_simultaneous <- joined_sf %>% filter(year(surveyDate) == year(time))

# Filters datasets based on four year difference between same time of surveyDate and time variables.
joined_past <- joined_sf %>% filter(
  (year(time) == 2011 & year(surveyDate) == 2015) |
  (year(time) == 2012 & year(surveyDate) == 2016) |
  (year(time) == 2013 & year(surveyDate) == 2017)
)

# Converts these two spatial data-sets to dataframes
joined_simultaneous <- st_drop_geometry(joined_simultaneous)
joined_past <- st_drop_geometry(joined_past)
```

I wanted to ensure there is enough of a representation of each category in the bleaching count as this will be the variable the four-years-behind and contemporary model will try to predict, and there was.
```{r}
# Produces histogram to visualise bleachCat variable
ggplot() + geom_histogram(data = bleachingData, aes(bleachCat), bins = 20)
```
I wanted to explore some of the variables in the eReefs data-set. We found that the ph variable has minimal representation in the first year of both the past joined and simultaneous data-sets. Due to this occurring in both data-sets roughly equally this isn't a concern and no action is needed.
```{r}
# Produces boxplots to visualise effect of ph over time
ggplot() + geom_boxplot(data = joined_past, aes(x = as.factor(time), y = ph))
ggplot() + geom_boxplot(data = joined_simultaneous, aes(x = as.factor(time), y = ph))
```
There didn't appear to be any significant outliers in other data-set for salt. 
```{r}
# Produces boxplots to visualise effect of salt over time
ggplot() + geom_boxplot(data = joined_past, aes(x = salt))
ggplot() + geom_boxplot(data = joined_simultaneous, aes(x = salt))
```
Although extremely small values, there are no need for adjustments here for the ma_n variable as the model we use will likely account for these  variables with multipliers.
```{r}
# Produces boxplots to visualise effect of ma_n over time
ggplot() + geom_boxplot(data = joined_past, aes(x = ma_n))
ggplot() + geom_boxplot(data = joined_simultaneous, aes(x = ma_n))
```
There does appear to be a major outlier in both data-sets, especially the four-years prior dataset, so we removed these outliers by removing total nitrogen values over 120.
```{r}
# Visualising the joined past and simultaneous data-sets and removing outliers
ggplot() + geom_boxplot(data = joined_past, aes(x = total_n))
ggplot() + geom_boxplot(data = joined_simultaneous, aes(x = total_n))

joined_past <- filter(joined_past, total_n < 120)
joined_simultaneous <- filter(joined_simultaneous, total_n < 120)
```
There did appear to be some trends of the environment variables predicting the bleaching category whereby the 2nd category tend to have the lowest or highest value for a few of the variables for the four years prior variables. There were no other noticeable trends.
```{r}
# Visualising data for joined_past via boxplots
ggplot() + geom_boxplot(data = joined_past, aes(x = total_n, y=as.factor(bleachCat)))
ggplot() + geom_boxplot(data = joined_past, aes(x = ph, y=as.factor(bleachCat)))
ggplot() + geom_boxplot(data = joined_past, aes(x = temp, y=as.factor(bleachCat)))
```

# Part One
Our client asked us to explore the claim that "Tropical Mid-Lateral Reefs have a higher probability of Coral Bleaching between 2014-2017 (time of El Niño)", so now we will proceed with data analysis to evaluate this claim. 

## Evaluating the Claim

### Maps for Yearly Exploration of Bleaching

First we wanted to explore via maps whether each reef has above average coral bleaching occurring, with reference to whether they are in the tropical mid-latitude zone. We calculated the mean to be 8.2 for global coral bleaching and so used this value to compare if a particular reef has above average bleaching. We removed rows where Average Bleaching is not 0 for this value calculation and plotting Reefs.

```{r}
# Discards reef rows with average bleaching of 0 and calculates the mean for the remaining reefs average bleaching.
x <- filter(reefCortadDataYears, Average_bleaching != 0)
mean(x$Average_bleaching)
```

```{r}
# In this chunk we produce 4 plots for each year as required by client to analyse whether zone affects probability of bleaching.

plots <- list()

# We iterate through a loop for each year
for (x in 2014:2017) {
  # We generate a year model as seen for each year which provides ggplot all info it needs to produce a map plot for that year.
  reefCortadDataYearsModel <- filter(reefCortadDataYears, Year == x)
  year_model <- reefCortadDataYearsModel[, c("Reef.Name", "Year", "Latitude.Degrees", "Longitude.Degrees","Average_bleaching")]
  year_model <- year_model %>% distinct(Reef.Name, Year, Latitude.Degrees, Longitude.Degrees, Average_bleaching)
  year_model <- year_model %>% arrange(!(Average_bleaching <= 8.2))
          
  # We generate a plot for that year with the given information regarding year model and plot info below to illustrate whether the average bleaching is above average, with red lines to identify the tropical mid-latitude.
  plot <- ggplot()+geom_polygon(data =map_data("world"), aes(x=long, y = lat, group = group), alpha=0.3)+
  geom_point(data = year_model, alpha = 0.5, aes(y=Latitude.Degrees, x= Longitude.Degrees,
    color=Average_bleaching>8.2), size=4) +  geom_hline(yintercept = -15, color = "red", linetype = "dashed", linewidth = 1)+  geom_hline(yintercept = 15, color = "red", linetype = "dashed", linewidth = 1)+scale_colour_viridis_d(option = "D") + theme_minimal() +  theme(
      panel.background = element_rect(color = "black"), plot.background = element_rect( color = NA)) + ggtitle(paste("Year:", x)) + labs(color = "Average", shape = "Reef Above Mean") + xlab("Longitude") + ylab("Latitude")
  
  # We then append this plot to the plots list above.
  plots[[as.character(x)]] <- plot
}

# Here we essentially print the plethora of plots in a grid.
grid.arrange(grobs = plots, ncol = 2, top = "Comparing if Reefs' Average Bleaching by Zone is above mean average")
```

Mid-latitude zones identified with red lines.

As can be seen in the above maps, there are clear trends despite a year (2015) where there was higher bleaching on average for outside the mid-latitude zone, it appeared there was consistently a greater average bleaching per year for reefs in the mid-latitude zones compared to in-between zones (15-20 above or below the equator) and outside mid-latitude zones. 

In 2014, it appears the below mean averages are sporadically scattered around the outside of the Tropical Mid-latitude zone, whereas lots of the above mean averages were clustered in the zone especially around the Pacific Ocean and South-East Asia. This indicates a greater probability of Coral Bleaching occurring in the Tropical Mid-latitude.

In 2015, it seems in general that the below mean averages are shared inside and outside the Tropical Mid-latitude, with more below mean averages inside arguably. This suggests interestingly a greater probability outside the Mid-Latitude overall.

In 2016, it appears in general that like 2014 the above mean averages tend to be inside the Tropical Mid-latitude, and below mean averages outside. This suggests interestingly a greater probability inside the Mid-Latitude.

In 2017, there appears to be less Reef information. Thus there is less information to reflect on in regards to the probabilities. Overall from the data here it seems rather 50:50 between inside and outside the Mid-Latitude maybe slightly favoring the Mid-Latitude again having a greater change of coral bleaching.

### Why these values?

Despite maps above suggesting above more likely average bleaching in mid-latitude zones in 2014, 2016, 2017, we felt a line chart would further add to the story in demonstrating our suspicions. 

```{r}
# In this chunk we want to produce a line chart and so we create a smaller version of the overall reef data set with a focus on average bleaching.

avg_bleaching_df <- reefCortadDataYears[, c("Reef.Name", "Year", "Latitude.Degrees", "Longitude.Degrees","Average_bleaching")]

avg_bleaching_df <- transform(avg_bleaching_df, in_zone = ifelse(abs(Latitude.Degrees)<20, "Inside Midlatitude Zone", "Outside Midlatitude Zone"))

avg_bleaching_df$in_zone <- as.factor(avg_bleaching_df$in_zone)
  
comparing_bleaching <- avg_bleaching_df[, c("Year","in_zone", "Average_bleaching")]

p <- comparing_bleaching %>% group_by(Year, in_zone) %>%
  summarise(average_value = mean(Average_bleaching, na.rm=TRUE), .groups = "drop")

ggplot(p, aes(x=Year, y = average_value, color = in_zone)) + geom_line(linewidth = 3) + scale_colour_viridis_d(option = "D") + ggtitle("Comparing Average Bleaching with Years and Zone") + ylab("Average Bleaching")
```

Higher averages of bleaching for mid-latitude reefs are made clear here apart from 2015. 

In 2014 it seems there was a high average of coral bleaching across Reefs in the Tropical Midlatitude zone, compared to the other zones. We felt this was due to a minor El Niño event in the Pacfic Ocean as claimed by [@PMEL] that only lasted between 2014-15. This indicates a higher probability of coral bleaching for Tropical Midlatitude zones rather than outer zones in 2014.

In 2015 average bleaching was higher outside the tropical midlatitude. We felt this may have been due to the "nothing" time between the minor and major El Niño events where there wasn't anything major, and natural variations with a more rapidly warming climate for outside the midlatitude.

```{r}
# In this chunk we want to produce a line chart and so we create a smaller version of the overall reef dataset with a focus on temperature.
temp_model <- reefCortadDataYears[, c("Reef.Name", "Year", "Latitude.Degrees", "Longitude.Degrees","Temperature_Mean")]

temp_model <- transform(temp_model, in_zone = ifelse(abs(Latitude.Degrees)<20, "Inside Midlatitude Zone", "Outside Midlatitude Zone"))

temp_model$in_zone <- as.factor(temp_model$in_zone)
  
comparing_temp <- temp_model[, c("Year","in_zone", "Temperature_Mean")]

p <- comparing_temp %>% group_by(Year, in_zone) %>%
  summarise(average_value = mean(Temperature_Mean, na.rm=TRUE), .groups = "drop")

ggplot(p, aes(x=Year, y = average_value, color = in_zone)) + geom_line(linewidth = 3) + scale_colour_viridis_d(option = "D") + ggtitle("Comparing Average Reef Temperature Mean with Years and Zone") + ylab("Average Temperature (K)")
```

In 2016 as seen the El Niño event was in full force, with Tropical midlatitude zones being hit slightly harder than outer zones, with almost a 5 average of coral bleaching for midlatitude reefs compared to approximately 4.3 for outer zones. Clearly a huge spike from the prior two years however, and both were hit hard. This again indicates a higher probability of coral bleaching for Tropical Midlatitude zones rather than outer zones in 2016.

In 2017 it appears after the El Niño event while both zones Reefs recovered, the mid-latitude zones still had higher average bleaching (3) compared to around 1.3 for outside. This indicates a higher probability of coral bleaching for Tropical Midlatitude zones rather than outer zones in 2017.

### Mean Thermal Stress Anomalies Exploration
Furthermore we wanted to explore Thermal Stress Anomalies. To compare if reefs were above average for this stat, we calculate the mean of thermal stress anomalies of reefs, and found it to be -1.57.

```{r}
# Calculates mean of the tsa means calculated for individual reefs.
mean(reefCortadDataYears$TSA_Mean)
```

```{r}
# In this chunk we want to produce a map and so we create a smaller version of the overall reef data-set with a focus on tsa visualizing reefs with above average tsa mean.
tsa_df <- reefCortadDataYears[, c("Reef.Name", "Latitude.Degrees", "Longitude.Degrees", "TSA_Mean")]
tsa_df <- tsa_df %>% distinct(Reef.Name, Latitude.Degrees, Longitude.Degrees, TSA_Mean)

tsa_df <- transform(tsa_df, in_zone = ifelse(abs(Latitude.Degrees)<20 & abs(Latitude.Degrees)>15, "Inbetween", ifelse(abs(Latitude.Degrees)<15, "Inside Midlatitude Zone", "Outside Midlatitude Zone")))

tsa_df$Above_Mean <- tsa_df$TSA_Mean > -1.57
tsa_df$in_zone <- as.factor(tsa_df$in_zone)

world_map <- map_data("world")
ggplot()+geom_polygon(data = world_map, aes(x=long, y = lat, group = group), alpha=0.3)+
geom_point(data = tsa_df, alpha = 0.4, aes(y=Latitude.Degrees, x= Longitude.Degrees,
  shape=Above_Mean, color = in_zone), size=4) + scale_colour_viridis_d(option = "D") + theme_minimal() +  theme(
    panel.background = element_rect(color = "black"), plot.background = element_rect(color = NA)
  ) + ggtitle("Comparing if Reefs' Average TSA by Zone is above mean average") + labs(color = "In Midlatititude Zone", shape = "Reef Above Global Mean (301K)") + xlab("Longitude") + ylab("Latitude")
```

As can be seen above there seems to be a very common trend where the reefs where there appears to be an above average number of Thermal Stress Anomalies between 2014-2017 seem to be in the Tropical Mid-latitude or the in-between area (15-20 Degrees from the Equator latitude-wise). This is important as according to [@Nature], TSA's have connections to Coral Bleaching, further evidencing Coral Bleaching being more likely to occur in the Tropical Mid-Latitude.

## Conclusion of Part One
We think the claim is valid as there were clear signs of the Tropical Mid-Latitude having a higher probability of coral bleaching in comparison to outside of this area. We showed a plethora of maps, and a line chart to demonstrate this being the case, except for in 2015 where we attributed them to a "nothing" period in the Pacific after a minor El Niño event in 2014, and some more rapid average temperature changes to outer mid-latitude reefs. Through another map we also showed that between 2014-2017 there were above average thermal stress anomalies, strange events that according to [@Nature], have links to Coral Bleaching. Through these visualizations we felt it appropriate to conclude the clients' claim to be true based on our findings.

## Evaluation and Improvements on Part One:
While we felt this part was success in that we gathered strong evidence of the clients claim we also made efficient use of resources, and time. In particular our map visualisations were extremely useful at presenting the data, and geom_polygon and ggplot complemented with effective plots. We felt the viridis package played a huge part in readability. And overall time was managed particularly well in this process.

In future endeavors to improve we would 
* Give more time to analyse the data set even if certain variables aren't directly correlated in order to better understand the domain or give us better ideas on how to make meaningful visualizations and produce even stronger evidence for our client.
* Try to make use of more than two types of graphs for our visualizations if we are going to produce a few different visualizations. It is easy to take a practical approach to this process where the graphs working well can be duplicated for other variables but a plethora of types of graphs may allow us to expand our lens and see data or information in different ways.
* Not overdo the amount of visualizations we produce for the client. The client only asked for a map visualization but we exceeded this amount to produce stronger evidence of their claim. However next time, it would be more suitable to request to the client whether it is allowed to go over the required amount so that we produce only exactly what they require.

### Side Note for Part One: A Cause for Concern 
```{r}
# Some  data manipulation
diversity_model <- reefCortadDataYears[, c("Reef.Name", "Year", "Latitude.Degrees", "Longitude.Degrees","Diversity")]

diversity_model <- transform(diversity_model, in_zone = ifelse(abs(Latitude.Degrees)<20, "Inside Midlatitude Zone", "Outside Midlatitude Zone"))

diversity_model$in_zone <- as.factor(diversity_model$in_zone)
  
comparing_diversity <- diversity_model[, c("Year","in_zone", "Diversity")]

p <- comparing_diversity %>% group_by(Year, in_zone) %>%
  summarise(average_value = mean(Diversity, na.rm=TRUE), .groups = "drop")

# This line chart plot visualises the average diversities of midlatitude vs outer zones over time.
ggplot(p, aes(x=Year, y = average_value, color = in_zone)) + geom_line(linewidth = 3) + scale_colour_viridis_d(option = "D") + ggtitle("Comparing Average Reef Diversity with Years and Zone")
```

As seen in the above line chart on Reef Diversity between 2014-2017 we wanted to emphasize that while we feel the probability of Coral Bleaching is greater in Tropical Mid-latitude states, it is important to consider both areas and prioritize preserving remaining species. From 2014-2017, the diversities of both areas each decreased hugely (Inside Mid-Latitude 425 down to nearly 300, and Outside 275 down to 150), and we must unite to prevent it from getting worse.

# Part Two

## Introduction
In this section we will use Random Forest modelling to try to produce accurate models using a eReefs dataset to predict bleaching categories in the bleach surveys data sets. This will be done for four years behind variables to bleach category information, and same time variables to bleach category information.

## Exploratory Data Analysis

## Contemporary Data used to predict Bleach Category
```{r}
# Treats the bleach categories as seperate categories (factors)
joined_simultaneous$bleachCat <- as.factor(joined_simultaneous$bleachCat)
```

```{r}
# Produces the train and test data-sets for the random forest model
set.seed(3338)
ind <- sample(2, nrow(joined_simultaneous), replace = TRUE, prob = c(0.7, 0.3))
train <- joined_simultaneous[ind==1,]
test <- joined_simultaneous[ind==2,]
```

```{r}
# Produces the random forest model
set.seed(3338) 
rf <- randomForest(bleachCat ~ temp + ph + ma_n + total_n + salt, data=train, proximity=TRUE, ntree = 1000)
```

```{r}
# Produces a confusion matrix and calculates its accuracy
# StackOverflow helped me to form the aesthetic style for the confusion matrix as cited in bibtex.
set.seed(3338)
p1 <- predict(rf, test)
cm <- confusionMatrix(p1, test$bleachCat)

plt <- as.data.frame(cm$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="20A387FF") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("Class_1","Class_2","Class_3","Class_4", "Class_5")) +
        scale_y_discrete(labels=c("Class_5","Class_4","Class_3","Class_2","Class_1")) + 
        scale_colour_viridis_d(option = "D")

round(cm$overall[1], 2)
```

### Verdict 
While this model's accuracy (0.46) may seem relatively weak, considering it has to choose five different categories for the response variable of bleachCat it is far better than random chance and the machine learning at play here is able to pick up some patterns in the data. Thus we would say it is in between a weak and moderate in terms of it's strength and could be useful to our client with some refinement to the model, i.e, changing the number of trees, adjust variables based on significance to data. However as the client just wanted me to compare contemporary and prior joined data we will not go through these additional steps.

## Four Years Prior Data used to Predict Bleach Category
```{r}
# Treats the bleach categories as seperate categories (factors)
joined_past$bleachCat <- as.factor(joined_past$bleachCat)
```

```{r}
# Produces the train and test data-sets for the random forest model
set.seed(3338)
ind_2 <- sample(2, nrow(joined_past), replace = TRUE, prob = c(0.7, 0.3))
train_2 <- joined_past[ind_2==1,]
test_2 <- joined_past[ind_2==2,]
```

```{r}
# Produces the random forest model
set.seed(3338)
rf_2 <- randomForest(bleachCat~ temp + ph + ma_n + total_n + salt, data=train_2, proximity=TRUE, ntree = 1000)
```

```{r}
# Produces a confusion matrix and calculates its accuracy
# StackOverflow helped me to form the aesthetic style for the confusion matrix as cited in bibtex.
set.seed(3338)
p2 <- predict(rf_2, test_2)
cm <- confusionMatrix(p2, test_2$bleachCat)

plt <- as.data.frame(cm$table)
plt$Prediction <- factor(plt$Prediction, levels=rev(levels(plt$Prediction)))

ggplot(plt, aes(Prediction,Reference, fill= Freq)) +
        geom_tile() + geom_text(aes(label=Freq)) +
        scale_fill_gradient(low="white", high="20A387FF") +
        labs(x = "Reference",y = "Prediction") +
        scale_x_discrete(labels=c("Class_1","Class_2","Class_3","Class_4", "Class_5")) +
        scale_y_discrete(labels=c("Class_5","Class_4","Class_3","Class_2","Class_1")) + 
        scale_colour_viridis_d(option = "D")

round(cm$overall[1], 2)
```

### Verdict
Like the prior model, this model is far better than random chance and the machine learning at play here is able to pick up some basic patterns in the data, with an accuracy of 0.48 (rounded to 2dp). In fact it is slightly stronger than the first model with a slighter greater accuracy. Again we would say it is in between a weak and moderate in terms of it's strength and could again be useful to our client with refinements steps as above. However as the client just wanted me to compare contemporary and prior joined data we will not go through these additional steps.

## Conclusion of Part Two
While both models weren't particularly strong and most likely wouldn't be of use to our client without further refinement, they helped to identify that the four-years-behind-joined environment variables to be better able to predict bleaching categories in the Great Barrier Reef with an accuracy of 0.48 compared to 0.46 for the time-simultaneously-joined joined variables. However with such a minimal difference of 0.02 for the accuracy, and the same accuracy when 500 ntrees were used instead of the 1000 used here when we tested before, it is clear there is very little meaningful difference between the two and their differences could be attributed to just chance. Therefore our evidence suggested that environmental variables measured four years prior are of the same use at predicting coral bleaching as the environmental variables captured at present.

## Evaluation and Improvements on Part Two
Again we felt this part was success in that we gathered the required evidence of up-to-date data being more useful. We also made efficient use of resources, and time. In particular the resource [@StackOverflow] greatly helped in providing an aesthetic confusion matrix basis which greatly improved the aesthetic requirement. We felt that Random Forest was a fit-for-purpose Machine Learning technique for the clients requirement. 

In future endeavors to improve we would
* Read the requirements carefully. We made mistakes in the process as we accidentally used the wrong data set required for this process assuming the first one was needed which cost us a lot of time.
* Check code carefully and don't hesitate to think outside the box. There was a simple error in the code that took many hours to fix. If code were checked, even in the most obvious setting, the error would've been fixed so much earlier.
* If given more time we would try to add more visualizations to compare the past and presently joined data-sets as this would improve clarity for clients, however it is more on the extraneous side of improvements here.
* In general I'd say with more time more data cleaning and EDA work as we don't think we managed time well for this part at the start.

# Summary
Overall in this two-part project, we gave the first client some strong evidence of Reefs inside the Tropical Mid-latitude having a greater probability of coral bleaching, via looking into yearly data of coral bleaching with maps, and a line chart, and then analyzing what zones had above average thermal stress anomalies. However, a further line chart showed concerning decreases in average Diversity in the Coral Reefs in both zones, evidencing the need for conservation. We required more than just one informative map visualization to make clear to them our data suggests a higher probability for Tropical Mid-Latitude zones.

In part two, for our second client we produced two Random Forest Models to predict bleaching categories via environmental variables aligned simultaneously, and environmental variables aligned four years in the past. In terms of our clients claim, for the data provided to use we found evidence for Reefs in the Coral Reef of environmental variables measured four years prior being equally valuable at predicting coral bleaching as the environmental variables captured at present.

# Use of External Resources
A general summary of external resources used for this project.

## Websites
For this project we have cited all resources and include [@__] to identify where they are referenced in the code wherever they are used.

## Chatbot Usage
In this project we used three chatbots to support me in this project and followed all rules of use. Here is how exactly each was used:

### Data3888 GenAI Agent
* Brainstorming part two methods 
  * This was something like is Random Forest an appropriate model to compare past-joint and present-joint data?
* How should we structure time throughout this project?
* Fixing a issue we couldn't seem to fix with the project (It didn't work but we sorted the issue myself): 
  * Why are my two random forest models getting the exact same accuracy (showing the p1 <- predict(rf, test) lines for each)
* Clarifying if my code folding use is correct

### Microsoft CoPilot
* We only tried to use this for fixing the long-lasting issue above but it didn't work. 

### ChatGPT
* We tried to use this for fixing the long-lasting issue but it didn't work. 
* A few times confirming certain code lines didn't have any errors 
* Identifying potential solutions to errors 
  * But we never used them. Only my own or online solutions
* Asking if 0.45 accuracy would be useful to my client
* Project Time Management 

## Citations used on Document